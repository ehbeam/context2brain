{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utilities import load_coordinates, load_dtm, load_mini_batches, plot_loss\n",
    "from utilities import report_macro, report_class, compute_roc, compute_prc, plot_curves\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "weight_decay = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = \"#426033\" # Color for plotting evaluation metrics and word clouds\n",
    "cmap = \"Blues\" # Color map for plotting brain structures\n",
    "prefix = \"emb\" # Prefix for plot file names\n",
    "n_top = 15 # Number of terms (i.e., inputs) to plot per brain structure (i.e., class)\n",
    "fname = \"figures/style/computer-modern/cmunss.ttf\" # Name of the font"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "## Brain activation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents   18155\n",
      "Structures  114\n"
     ]
    }
   ],
   "source": [
    "act_bin = load_coordinates()\n",
    "n_structs = act_bin.shape[1]\n",
    "print(\"{:12s}{}\".format(\"Documents\", act_bin.shape[0]))\n",
    "print(\"{:12s}{}\".format(\"Structures\", n_structs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension  100\n",
      "Terms                350543\n"
     ]
    }
   ],
   "source": [
    "vsm = pd.read_csv(\"data/text/glove_gen_n100_win15_min5_iter500_190428.txt\", \n",
    "                  sep = \" \", index_col=0, header=0)\n",
    "n_vocab = vsm.shape[0]\n",
    "n_emb = vsm.shape[1]\n",
    "print(\"{:21s}{}\".format(\"Embedding Dimension\", n_emb))\n",
    "print(\"{:21s}{}\".format(\"Terms\", n_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents   18155\n",
      "Terms       1542\n"
     ]
    }
   ],
   "source": [
    "dtm_bin = load_dtm()\n",
    "dtm_bin = dtm_bin[dtm_bin.columns.intersection(vsm.index)]\n",
    "n_terms = dtm_bin.shape[1]\n",
    "print(\"{:12s}{}\".format(\"Documents\", dtm_bin.shape[0]))\n",
    "print(\"{:12s}{}\".format(\"Terms\", n_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "## Training and dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {}\n",
    "for split in [\"train\", \"dev\"]:\n",
    "    splits[split] = [int(pmid.strip()) for pmid in open(\"data/splits/{}.txt\".format(split), \"r\").readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the inputs and outputs\n",
    "\n",
    "## Inputs \n",
    "\n",
    "Inputs are the mean of term embeddings for terms that occurred in a given article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehbeam/anaconda/envs/ontol/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/ehbeam/anaconda/envs/ontol/lib/python3.6/site-packages/numpy/core/_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "m = dtm_bin.shape[0]\n",
    "emb_cen = np.zeros((m, n_emb))\n",
    "for i in range(m):\n",
    "    terms = dtm_bin.columns[dtm_bin.values[i,:] == 1]\n",
    "    emb_cen[i,:] = np.mean(vsm.loc[terms].values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_cen = pd.DataFrame(emb_cen, index=dtm_bin.index, columns=range(n_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emb_cen.loc[splits[\"train\"]].transpose()\n",
    "X = X.fillna(0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "Outputs are labels for whether or not a given article reported a coordinate in each brain structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = act_bin.loc[splits[\"train\"]].transpose().values\n",
    "mini_batches = load_mini_batches(X, Y, mini_batch_size=batch_size, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_emb, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(100, 100)\n",
    "        self.fc5 = nn.Linear(100, 100)\n",
    "        self.dropout1 = nn.Dropout(p=0.5),\n",
    "        self.fc6 = nn.Linear(100, 100)\n",
    "        self.dropout2 = nn.Dropout(p=0.5),\n",
    "        self.fc7 = nn.Linear(100, 100)\n",
    "        self.dropout3 = nn.Dropout(p=0.5),\n",
    "        self.fc8 = nn.Linear(100, n_structs)\n",
    "        \n",
    "        # Xavier initialization for weights\n",
    "        for fc in [self.fc1, self.fc2, self.fc3, self.fc4,\n",
    "                   self.fc5, self.fc6, self.fc7, self.fc8]:\n",
    "            nn.init.xavier_uniform_(fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.dropout(x)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.dropout(x)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.dropout(x)\n",
    "        x = torch.sigmoid(self.fc8(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = F.binary_cross_entropy\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  25 \t Loss 0.004865\n",
      "Epoch  50 \t Loss 0.004637\n",
      "Epoch  75 \t Loss 0.004543\n",
      "Epoch 100 \t Loss 0.004384\n",
      "Epoch 125 \t Loss 0.004291\n",
      "Epoch 150 \t Loss 0.004326\n",
      "Epoch 175 \t Loss 0.004192\n",
      "Epoch 200 \t Loss 0.004229\n",
      "Epoch 225 \t Loss 0.004411\n",
      "Epoch 250 \t Loss 0.004340\n",
      "Epoch 275 \t Loss 0.004130\n",
      "Epoch 300 \t Loss 0.004213\n",
      "Epoch 325 \t Loss 0.004165\n",
      "Epoch 350 \t Loss 0.004189\n",
      "Epoch 375 \t Loss 0.004173\n",
      "Epoch 400 \t Loss 0.004138\n",
      "Epoch 425 \t Loss 0.004177\n",
      "Epoch 450 \t Loss 0.004072\n",
      "Epoch 475 \t Loss 0.004224\n",
      "Epoch 500 \t Loss 0.004045\n"
     ]
    }
   ],
   "source": [
    "net_file = \"models/classifier_{}.pt\".format(prefix)\n",
    "if not os.path.exists(net_file):\n",
    "    \n",
    "    running_loss = []\n",
    "    for epoch in range(n_epochs):  # Loop over the dataset multiple times\n",
    "        for i, data in enumerate(mini_batches):\n",
    "\n",
    "            # Get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(torch.from_numpy(inputs.T).float())\n",
    "            labels = Variable(torch.from_numpy(labels.T).float())\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Print running loss after each epoch\n",
    "        running_loss += [loss.item()]\n",
    "        if epoch % (n_epochs/20) == (n_epochs/20) - 1:\n",
    "            print(\"Epoch {:3d} \\t Loss {:6.6f}\".format(epoch + 1, running_loss[-1] / 100))\n",
    "    \n",
    "    # Export the trained model\n",
    "    torch.save(net.state_dict(), net_file)\n",
    "    \n",
    "    # Plot the loss\n",
    "    plot_loss(prefix, running_loss, xlab=\"Epoch\", ylab=\"Loss\", color=color)\n",
    "\n",
    "else:\n",
    "    net.load_state_dict(torch.load(net_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(data_set):\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = data_set[0]\n",
    "        inputs = Variable(torch.from_numpy(inputs.T).float())\n",
    "        labels = Variable(torch.from_numpy(labels.T).float())\n",
    "        outputs = net(inputs)\n",
    "        predictions = (outputs > 0.5).float() * 1\n",
    "        print(\"-\" * 50 + \"\\nMACRO-AVERAGED TOTAL\\n\" + \"-\" * 50)\n",
    "        report_macro(labels, predictions)\n",
    "        print(\"\\n\" + \"-\" * 50 + \"\\n\\n\")\n",
    "        for i in range(n_structs):\n",
    "            print(\"-\" * 50 + \"\\n\" + act_bin.columns[i].title().replace(\"_\", \" \") + \"\\n\" + \"-\" * 50)\n",
    "            report_class(labels[:,i], predictions[:,i])\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_curves(data_set, name): \n",
    "    with torch.no_grad():\n",
    "        inputs, labels = data_set[0]\n",
    "        inputs = Variable(torch.from_numpy(inputs.T).float())\n",
    "        labels = Variable(torch.from_numpy(labels.T).float())\n",
    "        pred_probs = net(inputs).float()\n",
    "        fpr, tpr = compute_roc(labels, pred_probs)\n",
    "        prec, rec = compute_prc(labels, pred_probs)\n",
    "        plot_curves(\"{}_roc\".format(name), fpr, tpr, diag=True, alpha=0.25,\n",
    "                    xlab=\"1 - Specificity\", ylab=\"Sensitivity\")\n",
    "        plot_curves(\"{}_prc\".format(name), rec, prec, diag=False, alpha=0.5,\n",
    "                    xlab=\"Recall\", ylab=\"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [16339 x 1542], m2: [100 x 100] at /Users/soumith/mc3build/conda-bld/pytorch_1549310147607/work/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6c45fa1e8fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mini_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreport_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}_train\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-a6a12958a79f>\u001b[0m in \u001b[0;36mreport_curves\u001b[0;34m(data_set, name)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_prc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1d65c0bf7dd0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [16339 x 1542], m2: [100 x 100] at /Users/soumith/mc3build/conda-bld/pytorch_1549310147607/work/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "train_set = load_mini_batches(X, Y, mini_batch_size=len(splits[\"train\"]), seed=42)\n",
    "report_curves(train_set, \"{}_train\".format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_metrics(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_dev = dtm_bin.loc[splits[\"dev\"]].transpose().values\n",
    "Y_dev = act_bin.loc[splits[\"dev\"]].transpose().values\n",
    "dev_set = load_mini_batches(X_dev, Y_dev, mini_batch_size=len(splits[\"dev\"]), seed=42)\n",
    "report_curves(dev_set, \"{}_dev\".format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_metrics(dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map a brain dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import font_manager\n",
    "from scipy.stats import zscore\n",
    "from wordcloud import WordCloud\n",
    "from utilities import load_atlas, mni2vox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute term activation maps\n",
    "\n",
    "Inputs are embeddings for each term. Outputs are probabilities for each brain structure predicted by the occurrence of a given term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = list(dtm_bin.columns)\n",
    "term_map = pd.DataFrame(index=act_bin.columns, columns=dtm_bin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, term in enumerate(terms):\n",
    "    inputs = vsm.loc[term].values\n",
    "    inputs = Variable(torch.from_numpy(inputs).float())\n",
    "    pred_probs = net(inputs).float().detach().numpy()\n",
    "    term_map[term] = pred_probs[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load coordinates for brain structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv(\"data/brain/labels.csv\", index_col=None, header=0)\n",
    "struct2coord = {}\n",
    "for struct, x, y, z in zip(c[\"PREPROCESSED\"], c[\"X\"], c[\"Y\"], c[\"Z\"]):\n",
    "    struct2coord[struct] = mni2vox(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 15 # Number of terms (i.e., inputs) to plot per structure (i.e., class)\n",
    "colors = [\"#873434\", \"#bc7a29\", \"#426033\", \"#5673ad\", \"#7f5796\"] * 50\n",
    "cmaps = [\"Reds\", \"Oranges\", \"Greens\", \"Blues\", \"Purples\"] * 50\n",
    "fname = \"figures/style/computer-modern/cmunss.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot brain maps and word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "for i, struct in enumerate(act_bin.columns):\n",
    "    struct = act_bin.columns[i]\n",
    "    x, y, z = struct2coord[struct]\n",
    "    if verbose:\n",
    "        print(\"{} (z={})\".format(struct.title().replace(\"_\", \" \"), int(z)))\n",
    "    if not verbose:\n",
    "        plt.ioff()\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(6,6))\n",
    "    gs1 = gridspec.GridSpec(1,2)\n",
    "    gs1.update(wspace=-20, hspace=-10)\n",
    "    fig.suptitle(c[\"PRESENTABLE_TITLE\"][i], y=0.79,\n",
    "                 fontproperties=font_manager.FontProperties(fname=fname, size=24))\n",
    "    \n",
    "    bg_img = image.load_img(\"data/brain/atlases/MNI152_T1_1mm_brain.nii.gz\")\n",
    "    bg_img = np.flip(np.rot90(bg_img.get_data()[:,:,int(z)]).astype(float), axis=1)\n",
    "    bg_img[bg_img == 0] = np.nan\n",
    "    bg_img = bg_img[10:198, 20:162]\n",
    "\n",
    "    bilateral_atlas = load_atlas()\n",
    "    struct_img = np.flip(np.rot90(bilateral_atlas.get_data()[:,:,int(z)]), axis=1)\n",
    "    struct_img[struct_img != i+1] = np.nan\n",
    "    struct_img[struct_img == i+1] = 1.0\n",
    "    struct_img[struct_img == 0] = np.nan\n",
    "    struct_img = struct_img[10:198, 20:162]\n",
    "    \n",
    "    ax[0].imshow(bg_img, cmap=\"Greys_r\", alpha=0.7, vmin=1)\n",
    "    ax[0].imshow(struct_img, cmap=cmaps[0], alpha=0.6, vmin=0, vmax=1)\n",
    "    for side in [\"left\", \"right\", \"top\", \"bottom\"]:\n",
    "        ax[0].spines[side].set_visible(False)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "\n",
    "    def color_func(word, font_size, position, orientation, \n",
    "               random_state=None, idx=0, **kwargs):\n",
    "        return colors[0]\n",
    "\n",
    "    top = term_map.loc[struct].sort_values(ascending=False)[:n_top]\n",
    "    vals = top.values\n",
    "    tkns = [t.replace(\"_\", \" \") for t in top.index]\n",
    "    cloud = WordCloud(background_color=\"rgba(255, 255, 255, 0)\", mode=\"RGB\", \n",
    "                      max_font_size=180, min_font_size=10, \n",
    "                      prefer_horizontal=1, scale=20, margin=3,\n",
    "                      width=1200, height=1400, font_path=fname, \n",
    "                      random_state=42).generate_from_frequencies(zip(tkns, vals))\n",
    "    ax[1].imshow(cloud.recolor(color_func=color_func, random_state=42))\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.savefig(\"figures/maps/{}/{}.png\".format(prefix, struct), \n",
    "                bbox_inches=\"tight\", dpi=250)\n",
    "    if verbose:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine into one figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\"figures/maps/{}/{}.png\".format(prefix, struct) for struct in act_bin.columns]\n",
    "img_w, img_h = Image.open(images[0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_w, pad_h = 60, 30\n",
    "img_w += pad_w * 2\n",
    "img_h += pad_h * 2\n",
    "n_row, n_col = 19, 6\n",
    "fig_w = n_col * img_w\n",
    "fig_h = n_row * img_h\n",
    "x_coords = list(range(0, fig_w, img_w)) * n_row\n",
    "y_coords = np.repeat(list(range(0, fig_h, img_h)), n_col)\n",
    "padding = (pad_w, pad_h, pad_w, pad_h)\n",
    "white = (255,255,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Image.new(\"RGB\", (fig_w, fig_h), color=white)\n",
    "for i, img in enumerate(images):\n",
    "    img = Image.open(img)\n",
    "    img = ImageOps.expand(img, padding, fill=white)\n",
    "    figure.paste(img, (x_coords[i], y_coords[i]))\n",
    "figure.save(\"figures/maps/{}_map.png\".format(prefix))\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ontol)",
   "language": "python",
   "name": "ontol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
